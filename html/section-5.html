<!DOCTYPE html>
<!--**************************************-->
<!--* Generated from MathBook XML source *-->
<!--*    on 2016-12-30T14:51:44-05:00    *-->
<!--*                                    *-->
<!--*   http://mathbook.pugetsound.edu   *-->
<!--*                                    *-->
<!--**************************************-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>GILA Matrix notation</title>
<meta name="Keywords" content="Authored in MathBook XML">
<meta name="viewport" content="width=device-width,  initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<script type="text/javascript" src="https://sagecell.sagemath.org/static/jquery.min.js"></script><script type="text/x-mathjax-config">
// contrib directory for accessibility menu, moot after v2.6+?
MathJax.Ajax.config.path["Contrib"] = "https://cdn.mathjax.org/mathjax/contrib";
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']],
    },
    TeX: {
        // [Contrib]accessibility menu moot after v2.6+?
        extensions: ["AMSmath.js", "AMSsymbols.js", "extpfeil.js", "autobold.js", "https://aimath.org/mathbook/mathjaxknowl.js", "[Contrib]/a11y/accessibility-menu.js", ],
        equationNumbers: { autoNumber: "none",
                           useLabelIds: true,
                           // JS comment, XML CDATA protect XHTML quality of file
                           // if removed in XSL, use entities
                           //<![CDATA[
                           formatID: function (n) {return String(n).replace(/[:'"<>&]/g,"")},
                           //]]>
                         },
        TagSide: "right",
        TagIndent: ".8em",
    },
    "HTML-CSS": {
        scale: 88,
    },
});
    </script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML-full"></script><link href="https://aimath.org/knowlstyle.css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="https://aimath.org/knowl.js"></script><script src="https://aimath.org/mathbook/js/lib/jquery.sticky.js"></script><script src="https://aimath.org/mathbook/js/lib/jquery.espy.min.js"></script><script src="https://aimath.org/mathbook/js/Mathbook.js"></script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://aimath.org/mathbook/stylesheets/mathbook-3.css" rel="stylesheet" type="text/css">
<link href="https://aimath.org/mathbook/mathbook-add-on.css" rel="stylesheet" type="text/css">
<link href="extra.css" rel="stylesheet" type="text/css">
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<div style="display:none;">\(\require{graphicx}\require{cancel}\newcommand{\divides}{\!\mid\!}
\newcommand{\tdiv}{\; \mbox{div} \;}
\newcommand{\restrict}[2]{#1 \,\rule[-4pt]{.125pt}{14pt}_{\,#2}}
\newcommand{\lcm}[2]{\mbox{lcm} (#1, #2)}
\renewcommand{\gcd}[2]{\mbox{gcd} (#1, #2)}
\newcommand{\Naturals}{{\mathbb N}}
\newcommand{\Integers}{{\mathbb Z}}
\newcommand{\Znoneg}{{\mathbb Z}^{\mbox{\tiny noneg}}}
\newcommand{\Enoneg}{{\mathbb E}^{\mbox{\tiny noneg}}}
\newcommand{\Qnoneg}{{\mathbb Q}^{\mbox{\tiny noneg}}}
\newcommand{\Rnoneg}{{\mathbb R}^{\mbox{\tiny noneg}}}
\newcommand{\Rationals}{{\mathbb Q}}
\newcommand{\Reals}{{\mathbb R}}
\newcommand{\Complexes}{{\mathbb C}}
\newcommand{\relQ}{\mbox{\textsf Q}}
\newcommand{\relR}{\mbox{\textsf R}}
\newcommand{\nrelR}{\mbox{\raisebox{1pt}{$\not$}\rule{1pt}{0pt}{\textsf R}}}
\newcommand{\relS}{\mbox{\textsf S}}
\newcommand{\relA}{\mbox{\textsf A}}
\newcommand{\Dom}[1]{\mbox{Dom}(#1)}
\newcommand{\Cod}[1]{\mbox{Cod}(#1)}
\newcommand{\Rng}[1]{\mbox{Rng}(#1)}
\newcommand{\aij}[2]{a_{#1\:\!#2}}
\newcommand{\bij}[2]{b_{#1\:\!#2}}
\newcommand{\suchthat}{\;\mid\;}
\newcommand{\lt}{ &lt; }
\newcommand{\gt}{ &gt; }
\newcommand{\amp}{ &amp; }
\)</div>
<header id="masthead"><div class="banner"><div class="container">
<a id="logo-link" href="../images/gilamonster.jpg" target="_blank"><img src="../images/gilamonster.jpg"></a><div class="title-container">
<h1 class="heading"><span class="title">A Gentle Introduction to Linear Algebra</span></h1>
<p class="byline">Joe Fields</p>
</div>
</div></div>
<nav id="primary-navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="previous-button toolbar-item button" href="section-transformations.html">Previous</a><a class="up-button button toolbar-item" href="chapter-1.html">Up</a><a class="next-button button toolbar-item" href="chapter-2.html">Next</a>
</div>
<button class="sidebar-right-toggle-button button active">Annotations</button>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="section-transformations.html">Previous</a><a class="up-button button toolbar-item" href="chapter-1.html">Up</a><a class="next-button button toolbar-item" href="chapter-2.html">Next</a>
</div>
</div></nav></header><div class="page">
<aside id="sidebar-left" class="sidebar"><div class="sidebar-content">
<nav id="toc"><h2 class="link"><a href="frontmatter-1.html"><span class="title">Front Matter</span></a></h2>
<ul>
<li><a href="colophon-1.html">Colophon</a></li>
<li><a href="dedication-1.html">Dedication</a></li>
<li><a href="acknowledgement-1.html">Acknowledgements</a></li>
<li><a href="foreword-1.html">Foreword</a></li>
<li><a href="preface-1.html">Preface</a></li>
</ul>
<h2 class="link active"><a href="chapter-1.html"><span class="codenumber">1</span><span class="title">Introduction</span></a></h2>
<ul>
<li><a href="section-start.html">Getting started</a></li>
<li><a href="section-sys_eqs.html">Systems of equations</a></li>
<li><a href="section-vectors.html">Vector equations</a></li>
<li><a href="section-transformations.html">Transformations</a></li>
<li><a href="section-5.html" class="active">Matrix notation</a></li>
</ul>
<h2 class="link"><a href="chapter-2.html"><span class="codenumber">2</span><span class="title">RREF</span></a></h2>
<ul>
<li><a href="section-6.html">Triangular systems</a></li>
<li><a href="section-7.html">Echelon form</a></li>
<li><a href="section-rref.html">RREF</a></li>
<li><a href="section-row-ops.html">Row operations and Gaussian elimination</a></li>
<li><a href="section-10.html">Solving linear systems</a></li>
</ul>
<h2 class="link"><a href="chapter-3.html"><span class="codenumber">3</span><span class="title">Vectors</span></a></h2>
<ul>
<li><a href="section-11.html">Vectors and scalars</a></li>
<li><a href="section-12.html">The matrix-vector product</a></li>
<li><a href="section-13.html">Homogeneous and non-homogeneous systems</a></li>
<li><a href="section-14.html">Matrix-matrix products</a></li>
<li><a href="section-15.html">Vector spaces - an introduction</a></li>
<li><a href="section-16.html">Dependence and independence</a></li>
<li><a href="section-17.html">Bases and dimension</a></li>
</ul>
<h2 class="link"><a href="chapter-4.html"><span class="codenumber">4</span><span class="title">Determinants</span></a></h2>
<ul>
<li><a href="section-18.html">Torque, Area and Volume</a></li>
<li><a href="section-19.html">Determinants by recursion</a></li>
<li><a href="section-20.html">Formal definition</a></li>
</ul>
<h2 class="link"><a href="chapter-5.html"><span class="codenumber">5</span><span class="title">The spectral decomposition</span></a></h2>
<ul>
<li><a href="section-21.html">Diagonal and diagonalizable systems</a></li>
<li><a href="section-22.html">Eigenvalues and eigenvectors</a></li>
<li><a href="section-23.html">Jordan form</a></li>
<li><a href="section-24.html">The Singular value decomposition</a></li>
</ul>
<h2 class="link"><a href="chapter-6.html"><span class="codenumber">6</span><span class="title">Algebraic structures</span></a></h2>
<ul>
<li><a href="section-25.html">Groups, Rings and Fields</a></li>
<li><a href="section-26.html">Modules</a></li>
<li><a href="section-27.html">Algebras</a></li>
<li><a href="section-28.html">Inner product spaces</a></li>
</ul>
<h2 class="link"><a href="chapter-7.html"><span class="codenumber">7</span><span class="title">Abstract vector spaces</span></a></h2>
<ul>
<li><a href="section-29.html">Vector spaces</a></li>
<li><a href="section-30.html">Infinite dimensional spaces</a></li>
<li><a href="section-31.html">Hilbert space</a></li>
<li><a href="section-32.html">Fourier analysis</a></li>
</ul>
<h2 class="link"><a href="backmatter-1.html"><span class="title">Back Matter</span></a></h2>
<ul></ul></nav><div class="extras"><nav><a class="feedback-link" href="http://osj1961.github.io/gila/">Feedback</a><a class="mathbook-link" href="https://mathbook.pugetsound.edu">Authored in MathBook XML</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://cdn.mathjax.org/mathjax/badge/badge.gif" border="0" alt="Powered by MathJax"></a></nav></div>
</div></aside><main class="main"><div id="content" class="mathbook-content"><section class="section" id="section-5"><header title="Section 1.5 Matrix notation"><h1 class="heading hide-type" alt="Section 1.5 Matrix notation">
<span class="type">Section</span><span class="codenumber">1.5</span><span class="title">Matrix notation</span>
</h1></header><p id="p-154">The three seemingly distinct viewpoints we've considered are unified by the concept of a <em class="terminology">matrix</em>.</p>
<p id="p-155">The word “matrix” is from Latin.  The word entered the English language with a variety of meanings — in Latin it means <!--Style me with CSS--><em>womb</em>.   In mathematics, matrix (pl. matrices) always means a table containing numerical values.  It is rather hard to guess how a word meaning “uterus” could get morphed into one meaning “table of numbers”, but languages are funny that way…
</p>
<p id="p-156">Generally speaking, a table of numbers will have some arbitrary number of rows and of columns.  There are some special cases that we'll need to talk about, but let's look at the general situation first.  We'll use the variable \(m\) to refer to the number of rows in a matrix and the variable \(n\) to refer to the number of columns.  We'll use upper-case letters (about 90% of the time: \(A\)) to refer to the whole table as a single entity, in which case we'll speak of \(A\) being an \(m \times n\) matrix.  The entries of a matrix will usually be denoted using the corresponding lower-case letter with <!--Style me with CSS--><em>two</em> subscripts.  This is (hopefully) reminiscent of the doubly-indexed quantities we saw near the end of Section <a href="section-transformations.html" alt="Section 1.4 Transformations" title="Section 1.4 Transformations">1.4</a>; the components of a linear transformation.
</p>
<div class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-example-7" id="example-7"><article class="example-like"><h5 class="heading">
<span class="type">Example</span><span class="codenumber">1.5.1</span><span class="title">matrix notation</span>
</h5></article></a></div>
<div id="hk-example-7" style="display: none;" class="tex2jax_ignore"><article class="example-like"><p id="p-157">Here are a couple of matrices:
	\begin{equation*} A = \left[ \begin{array}{ccc} 1 \amp 4 \amp 9 \\ 7 \amp \pi \amp 42 \end{array} \right] \quad \mbox{and} \quad B = \left[ \begin{array}{cc} -1 \amp 11 \\ -3 \amp e \end{array} \right]\end{equation*}
</p>
<p id="p-158">Notice how we are referring to the entire tables with the variables \(A\) and \(B\)?  If we need to refer to the individual entries of a matrix we'll write things like \(\aij{2}{3} = 42\) (the number in the 2nd row and 3rd column of \(A\) is 42), or \(\bij{1}{2} = 11\) (the number in the 1st row, 2nd column of \(B\) is 11).
</p>
<p id="p-159">It's also fairly common to ignore this lower-case convention!  That is, you may also see things like \(A_{1\:\!3} = 9\) and \(B_{2\:\!2} = e\).
</p></article></div>
<p id="p-160">Now to the special cases.  When the number of columns is \(n=1\), the matrix is known as a <em class="terminology">column vector</em>.  When the number of rows is \(m=1\), the matrix is known as a <em class="terminology">row vector</em>.  There is clearly a choice to be made as to whether the things we have been referring to as (merely) “vectors” are going to be represented as column vectors, or as row vectors.  Here's a surprising thing!  Your Calculus teachers and I (up until now) have been lieing to you.  When we wrote vectors as (for example) \(\vec{v} = \langle 1, 2, 3 \rangle\), it was only for convenience.  A row of numbers fits more easily on the page than a column does.  For a variety of reasons it makes sense to treat vectors as columns of numbers, not rows.
</p>
<p id="p-161">There is an operation known as <em class="terminology">transposition</em> that changes row vectors into column vectors and <i class="foreign">vice versa</i>.  The <em class="terminology">transpose</em> of a matrix is indicated by a superscript T, the rows of the transposed matrix are the columns of the original matrix and its columns are the original matrix's rows.  This idea (interchanging rows and columns) is surprisingly important and we'll be using it quite a bit in the future.  For the moment let's just notice that it gives us a nice way to write a column vector — with the typographical advantage that the components appear in a row!
</p>
<p id="p-162">To summarize what the last few paragraphs have said: It is technically not right to write \(\vec{v} = \langle 1, 2, 3 \rangle\), we should really write \(\vec{v} = \left[ \begin{array}{c} 1 \\ 2\\ 3 \end{array} \right]\), but that takes up too much vertical space so instead we write \(\vec{v} = [ 1 \; 2 \; 3 ]^T\).  This may all seem like too high of a price to pay for accuracy, but it will pay future dividends if we start thinking now about rows and columns and how to switch between them.
</p>
<p id="p-163">If we only had row and column vectors to worry about we'd probably find some other way to distinguish them — maybe there'd be red vectors and blue vectors!
</p>
<article class="remark-like" id="note-1"><h5 class="heading">
<span class="type">Note</span><span class="codenumber">1.5.2</span>
</h5>
<p id="p-164">In Physics (especially in the Tensor Analysis which is used in e.g. General Relativity) they distinguish between covariant and contravariant indices.  An entity with a single contravariant index is a vector, if instead there is a single covariant index it is known as a co-vector.  These concepts aren't identical to row/column vectors, but nevertheless, contravariant vectors are usually written as columns and covariant vectors as rows.</p></article><p id="p-165">By convention there is no need to refer to the entries of a row or column vector using double indices — one of them would always be 1 so we can omit it.  When we have more general matrices, where \(m\) and \(n\) are both greater than \(1\), the roles of rows and columns are more evident and two indices will be necessary to refer to the entries.
</p>
<p id="p-166">One useful way to think about matrices is the following:  When we write down a system of equations, a lot of the symbols that we write are redundant.  If we eliminate all of the stuff that is utterly predictable we are left with a table of numbers — in other words, a matrix.  So one way to think of matrices is that they are highly abbreviated ways of referring to a system of linear equations.  In this scheme the rows of the matrix correspond to the individual equations in the system and the columns contain all the
coefficients that multiply a given variable.  A short example will probably help:
</p>
<div class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-example-8" id="example-8"><article class="example-like"><h5 class="heading">
<span class="type">Example</span><span class="codenumber">1.5.3</span><span class="title">Converting a linear system to matrix form</span>
</h5></article></a></div>
<div id="hk-example-8" style="display: none;" class="tex2jax_ignore"><article class="example-like"><p id="p-167">
Consider the following system of \(3\) equations in \(4\) variables.
\begin{equation*}
\begin{alignedat}{8}
   x_1  \amp {}+{} \amp   x_2 \amp       \amp      \amp {}+{} \amp 3 x_4 \amp {}={} \amp 101 \\
 2 x_1  \amp {}-{} \amp   x_2 \amp {}+{} \amp x_3  \amp {}+{} \amp x_4 \amp {}={} \amp 102 \\
        \amp       \amp 3 x_2 \amp {}-{} \amp x_3  \amp {}+{} \amp 2x_4 \amp {}={} \amp 103
\end{alignedat}
\end{equation*}
</p>
<p id="p-168">Now we'll take one step backwards before proceeding two steps forward.  If a variable appears, but has no coefficient, that just means the coefficient is \(1\).  If a variable doesn't appear at all, that means the coefficient is \(0\).
Finally, if we see subtraction we can always replace it by addition (by putting a minus sign on the coefficient).  So, let's re-express this system in a fully anal-retentive way…

 \begin{equation*}
\begin{alignedat}{8}
 1x_1  \amp {}+{} \amp  1x_2 \amp {}+{} \amp  0 x_3  \amp {}+{} \amp 3 x_4 \amp {}={} \amp 101 \\
 2x_1  \amp {}+{} \amp {-1}x_2 \amp {}+{} \amp  1 x_3  \amp {}+{} \amp 1 x_4 \amp {}={} \amp 102 \\
 0x_1  \amp {}+{} \amp  3x_2 \amp {}+{} \amp {-1} x_3  \amp {}+{} \amp 2 x_4 \amp {}={} \amp 103
\end{alignedat}
\end{equation*}
</p>
<p id="p-169">Okay, so now the promised two steps forward.  First, notice that in every equation in the system every variable is present and they all appear in ascending order.  If we were only given the lists of coefficients we'd easily be able to reconstruct the equations.  So, we're going to eject all of the plus signs and all of the variables with all of those subscripts.  We just won't deign to write them down! Sometimes it's a good idea to imagine their presence but it certainly isn't necessary to  Also, the equals signs that separate the left- and right-hand sides of the equations always come before the very last number.  There really isn't a lot of information conveyed by the appearance of those equals signs, but we usually keep a slight vestige of them around — a thin vertical line separates the last column of the matrix form from everything else.  So, with no further ado, here is the matrix form of this system:

\begin{equation*}
\left[ \begin{array}{rrrr|r}
 1 \amp  1 \amp  0 \amp 3  \amp 101 \\
 2 \amp {-1} \amp  1  \amp 1 \amp  102 \\
 0 \amp  3 \amp {-1}  \amp 2  \amp 103
\end{array} \right]
\end{equation*}
</p></article></div>
<p id="p-170">In the previous example the final matrix we wrote is actually known as the <em class="terminology">augmented matrix</em> of the system.  Sometimes it is a good idea to separate out the part of the matrix that appears to the left of the thin vertical line.  That part is known as the <em class="terminology">coefficient matrix</em> of the system.  This isn't just pedantry!  In many real-world applications we need to solve bunches of linear systems that all have the same coefficient matrix — so they only differ in the final column (a.k.a. the <em class="terminology">augmented column</em>) of their augmented  matrices.  We can take advantage of such a situation, essentially solving all of the systems while only doing the work of solving the first one!
</p>
<p id="p-171">Matrix notation was probably invented purely out of laziness.  When we use the Re-ordering, Scaling and Combining operations that we introduced in Section <a href="section-sys_eqs.html" alt="Section 1.2 Systems of equations" title="Section 1.2 Systems of equations">1.2</a>, we find ourselves having to re-copy the entire
system over and over.  By switching to matrix notation we get a considerable savings in effort.  The operations that we
originally developed to use on equations now become operations that one can apply to the rows of a matrix — a.k.a. row operations — which we will study in much greater depth in Section <a href="section-row-ops.html" alt="Section 2.4 Row operations and Gaussian elimination" title="Section 2.4 Row operations and Gaussian elimination">2.4</a>. Regardless of the origins of matrix notation, nowadays we don't think of matrices only in terms of being abbreviations for linear systems.  They have taken on a life of their own!  
</p>
<p id="p-172">There are two features of matrices that we'll explore in the remainder of this section.  The first is that matrices may be thought of as “funny shaped” vectors.  The second is that, under certain conditions, we can multiply matrices.  If you've already studied multi-variable calculus (and perhaps even if you haven't) you'll have run into the dot product (a.k.a. scalar product) and the cross product (a.k.a. vector product) in \(\Reals^3\).  No matter what the dimension of the space, there is always a dot product.  On the other hand, there is usually nothing analogous to the cross product — it depends on a very special coincidence, an odd fact about the space \(\Reals^3\).  The dot product is a way of multiplying vectors, but the product is <!--Style me with CSS--><em>not</em> a vector.  On the other hand, the cross product <!--Style me with CSS--><em>does</em> result in a vector.  Matrices (as “funny shaped” vectors) give us a way of multiplying vectors and getting other vectors.
</p>
<p id="p-173">The most important thing with vectors is that we need to be able to add them.  The second most important thing is that we should know how to scale them.  
</p>
<p id="p-174">If \(A\) and \(B\) are matrices, what would it mean to add them?  As was the case with vectors, it doesn't make any sense to add them unless they are the same size.  With vectors they needed to have the same number of components in order to even think about adding them.  With matrices the restriction is even stronger; they need to have the same number of rows <!--Style me with CSS--><em>and</em> of columns.  Provided that that restriction is met, we just add the corresponding entries.
</p>
<article class="definition-like" id="definition-15"><h5 class="heading">
<span class="type">Definition</span><span class="codenumber">1.5.4</span><span class="title">matrix addition</span>
</h5>
<p id="p-175">If \(A\) and \(B\) are both \(m \times n\) matrices, their sum, \(A+B\) is also an \(m \times n\) matrix. For all integers \(i\) and \(j\) satisfying \(1 \leq i \leq m\) and \(1 \leq j \leq n\), the entry in the \(i\)th row and \(j\)th column of \(A+B\) is \(\aij{i}{j} + \bij{i}{j}\).
</p></article><p id="p-176">Scaling also works in much the same way as it did with vectors.  If we multiply a scalar and a matrix, every entry of the matrix is multiplied by the scalar.
</p>
<article class="definition-like" id="definition-16"><h5 class="heading">
<span class="type">Definition</span><span class="codenumber">1.5.5</span><span class="title">matrix scaling</span>
</h5>
<p id="p-177">If \(A\) is an \(m \times n\) matrix, and \(s\) is a real number, the scalar product, \(sA\) is also an \(m \times n\) matrix. For all integers \(i\) and \(j\) satisfying \(1 \leq i \leq m\) and \(1 \leq j \leq n\), the entry in the \(i\)th row and \(j\)th column of \(sA\) is \(s\cdot\aij{i}{j}\).
</p></article><div class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-example-9" id="example-9"><article class="example-like"><h5 class="heading">
<span class="type">Example</span><span class="codenumber">1.5.6</span><span class="title">vector properties of matrices</span>
</h5></article></a></div>
<div id="hk-example-9" style="display: none;" class="tex2jax_ignore"><article class="example-like"><p id="p-178">Let \(A = \left[ \begin{array}{cc} 1 \amp -1 \\ -1 \amp 2 \end{array}\right]\) and \(B = \left[ \begin{array}{cc} 0 \amp 1 \\ 2 \amp 3 \end{array}\right]\).  These matrices are both \(2 \times 2\) so their sum is defined.
    \begin{equation*} A+B = \left[ \begin{array}{cc} 1 \amp 0 \\ 1 \amp 5 \end{array}\right]\end{equation*}
</p>
<p id="p-179">Let's also provide an example of scaling.  If we scale the matrix \(A\) by a factor of \(3\) we get
\begin{equation*} 3A = \left[ \begin{array}{cc} 3 \amp -3 \\ -3 \amp 6 \end{array}\right]\end{equation*}
</p></article></div>
<article class="exercise-like" id="exercise-4"><h5 class="heading">
<span class="type">Exercise</span> <span class="codenumber">1.5.7</span> <span class="title">linear combinations of matrices</span>
</h5>
<p id="p-180">Suppose that \(A\) and \(B\) are the following \(2 \times 3\) matrices:
\begin{equation*}A = \left[ \begin{array}{ccc} 1 \amp 2 \amp 3 \\ 4 \amp 5 \amp 6 \end{array}\right] \quad \mbox{and} \quad B = \left[ \begin{array}{ccc} 3 \amp 5 \amp 7 \\ 4 \amp 6 \amp 8 \end{array}\right]\end{equation*}
What is \(5A-2B\)?
</p></article><div class="hidden-knowl-wrapper">
<span class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-solution-6" id="solution-6"><span class="">Solution</span></a></span><span id="hk-solution-6" style="display: none;" class="tex2jax_ignore"><div class="remark-like"><p id="p-181">\begin{equation*} 5A-2B = \left[\begin{array}{ccc} -1 \amp 0 \amp 1 \\ 12 \amp 13 \amp 14 \end{array}\right].\end{equation*}</p></div></span>
</div>
<p id="p-182">So that was nice!  Once we know how to add matrices and how to multiply them by scalars, we can form linear combinations.  Next we'll look at multiplying our funny shaped vectors…
</p>
<p id="p-183">The easiest example (and also a <!--Style me with CSS--><em>very</em> instructive example) of multiplying vectors is the product of a 
row and a column vector.  Provided they have the same number of entries, a row vector times a column vector produces 
a \(1 \times 1\) matix — also known as a real number.  You have almost certainly seen this before!  The dot product of two vectors is actually a row/column matrix product.  In fact, in many settings they will
write \(\vec{x}^T\vec{y}\) rather than \(\vec{x} \cdot \vec{y}\) when referring to the dot product.  As you move towards more advanced math the tendency will be to call this the “inner product” rather than the “dot product”, one reason to make the change (other than it sounds more sophisticated) is that there is also an “outer product” of vectors which is what you get if you multiply a column times a row.  As we'll see shortly, \(\vec{x}^T\vec{y}\) and 
\(\vec{x}\vec{y}^T\) are <!--Style me with CSS--><em>extremely</em> different!  Anyway, we need to do this row/column product as a component of the general matrix product computation so let's proceed to over-explain it by some huge factor…
</p>
<p id="p-184">If you've ever done the challenge where you rub your belly in a circular motion while simultaneously patting your head, then this shouldn't be too difficult.  What you need to do is trace across the entries of a row with your left index finger, while simultaneously tracing down the entries of a column with your right index finger.  As you encounter the entries you multiply them and keep a running tally of the sum of these products.
</p>
<div class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-example-10" id="example-10"><article class="example-like"><h5 class="heading">
<span class="type">Example</span><span class="codenumber">1.5.8</span><span class="title">an inner product</span>
</h5></article></a></div>
<div id="hk-example-10" style="display: none;" class="tex2jax_ignore"><article class="example-like"><p id="p-185">Suppose 
	\begin{equation*}\vec{x} = \left[ \begin{array}{c} 3 \\ 1 \\ -2 \\ 5 \end{array} \right] \quad \mbox{and} \quad  \vec{y} = \left[ \begin{array}{c} -1 \\ 6 \\ 4 \\ 7 \end{array} \right] \end{equation*}
then the inner product of these two vectors (\(\vec{x}^T\vec{y}\)) is the following row/column matrix computation:
\begin{equation*}\vec{x}^T \vec{y} \quad = \quad \left[ \begin{array}{cccc} 3 \amp 1 \amp -2 \amp 5 \end{array} \right]  \cdot \left[ \begin{array}{c} -1 \\ 6 \\ 4 \\ 7 \end{array} \right] \quad = \quad 3\cdot (-1) + 1\cdot 6 + (-2)\cdot 4 + 5\cdot 7 \quad = \quad 30\end{equation*}
</p></article></div>
<p id="p-186">Notice that if the vectors had different lengths (I mean “lengths” as in “number of entries”) the process we've described wouldn't work out so good…  One of your fingers would be out of entries before the other!  This is our first example of an idea known as <em class="terminology">conformability</em>. Suppose we have a row vector of length \(m\) (that is, a \(1 \times m\) matrix) and a column vector of length \(n\) (in other words a \(n \times 1\) matrix), then they are <em class="terminology">conformable</em> if \(m=n\) and if \(m\neq m\) they are <!--Style me with CSS--><em>not</em> conformable, in which case the matrix product can't be computed.
</p>
<p id="p-187">The general rule for computing matrix products involves doing this row/column product multiple times. Suppose \(A\) is a \(p \times q\) matrix and \(B\) is an \(r \times s\) matrix.  The product \(AB\) will be a \(p \times s\) matrix, but it can only be computed if \(q=r\).  The entry in the \(p\)-th row and \(s\)-th column of the result is obtained using the \(p\)-th row of \(A\) and the \(s\)-th column of \(B\).  When you physically write the sizes of the multiplicands next to one another, the inner two numbers must match and the outer two numbers tell you the size of the result!
</p>
<article class="definition-like" id="definition-17"><h5 class="heading">
<span class="type">Definition</span><span class="codenumber">1.5.9</span><span class="title">matrix conformability</span>
</h5>
<p id="p-188">Suppose \(A\) is a \(p \times q\) matrix and \(B\) is an \(r \times s\) matrix.  If \(q=r\) these matrices are <em class="terminology">conformable</em> and the product \(AB\) can be computed.</p></article><article class="remark-like" id="note-2"><h5 class="heading">
<span class="type">Note</span><span class="codenumber">1.5.10</span>
</h5>
<p id="p-189">Conformability has a directionality.  If \(A\) and \(B\) are conformable it is not necessarily the case that \(B\) and \(A\) are conformable.  Matrices fail to obey the commutative law in a fairly spectacular way!  It is <!--Style me with CSS--><em>not</em> generally the case that \(AB = BA\).  Indeed, quite often it is <!--Style me with CSS--><em>impossible</em> to compute the product \(BA\), even given that it <!--Style me with CSS--><em>is</em> possible to compute \(AB\).
</p></article><article class="definition-like" id="definition-18"><h5 class="heading">
<span class="type">Definition</span><span class="codenumber">1.5.11</span><span class="title">matrix product</span>
</h5>
<p id="p-190">Suppose we are given two matrices, \(A\) and \(B\) that are conformable for matrix multiplication, further, suppose that \(A\) is \(m \times n\) and \(B\) is \(n \times p\).  The matrix product \(AB\) will be an \(m \times p\) matrix.  The entry in the \(i\)-th row and \(j\)-th column of \(AB\) is

\begin{equation*} AB_{ij} \; = \; \sum{k=1}^n A_{ik}\cdot B_{kj}\end{equation*}
</p></article></section></div></main>
</div>
</body>
</html>
