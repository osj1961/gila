<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns:xi="http://www.w3.org/2001/XInclude">
<title>Introduction</title>

<introduction>
<p>The subject we are about to study, Linear Algebra, sounds like it might have something to do with lines and doing algebra with them.  This is true if you are willing to think metaphorically<ellipsis /> It might be somewhat closer to the truth if we were to say that Linear Algebra is about learning to understand higher dimensions.  We'll be surprisingly far along in our study of the topic before we can precisely define what <q>dimension</q> actually means, but we expect that you have some notion already: the Euclidean plane where we studied Geometry is two dimensional, the world we live in is three dimensional, Albert Einstein taught us to view the world not just as space <mdash /> but as space-time <mdash /> a four dimensional concept.  We needn't jump off into super advanced physics (or science fiction for that matter) in order to understand higher dimensionality.  Dimension, at least informally, just means the number of real numbers it takes to describe something. Locating a point in three-dimensional space requires three numbers <mdash /> usually <m>x</m>, <m>y</m> and <m>z</m>.  If we are keeping track of aircraft, knowing where they are in 3-space is certainly necessary, but it might also be a good idea to keep abreast of <em>which way they are going</em>!  To truly understand an aircraft's state, one needs to have six numbers: <m>x</m>, <m>y</m> and <m>z</m>, but also the velocity components <m>x'</m>, <m>y'</m> and <m>z'</m>.  This make the state of an airplane 6-dimensional.  Perhaps this is why air traffic controllers make the big bucks.
</p>

<p>The 6-dimensionality of an aircraft's state may seem somewhat artificial.  Aren't we really just dealing with two separate 3-dimensional entities?
</p>

<p>In Economics there is a high-dimensional entity known as the Leontief Input-Output model.  In
this model the state of an Economic system is described by a large number of real quantities, one for each sector of the economy.  In a 1965 Scientific American article Wassily Leontief (who won a Nobel prize for this work) described his model in terms of a <q>toy example</q> where the economy was divided into 82 sectors.  Today one could easily develop a Leontief I/O model where the economy was divided up into a million sectors.  Perhaps this is why Economists make even bigger bucks.
</p>

<p>When we do Linear Algebra in two dimensions we are indeed talking about lines.  One of the classic problems is to figure out whether two lines intersect and if so, where.  This is a situation where our ability to visualize things in two dimensions can lead us straight to the answer.  That is certainly not the case in a million (or even in six) dimensions.  Fortunately, there are calculational techniques that work (and even work fairly quickly on a good computer) in
just about any number of dimensions you may be interested in.
</p>

<p>There are three different ways of looking at linear algebra problems: systems of linear equations, vector equations, and transformations.  These three views actually represent the same underlying structure, just in different ways.  There are various situations where one of these three viewpoints is preferable, so it is a good idea to be able to switch back and forth between these representations.
</p>

<p>In Section <xref ref="section-start" /> we will look at the same (really easy) problem from each of these 3 perspectives.
</p>

</introduction>

<section xml:id="section-start">
<title>Getting started</title>
<p>The first problem we're going to look at is fairly trivial.  I bet you can solve this in your head:</p>

<blockquote>
  <p>I'm thinking of two numbers <m>x</m> and <m>y</m>.  Their sum is 42, and their difference is 6.  What are they?</p>
</blockquote>

<p>This word problem can be instantly translated into a pair of equations.  Later, when we have more sophisticated problems there may be many more unknown quantities and there may be many more equations.  Here we are dealing with a system of equations having 2 equations in 2 unknowns.

<md>
<mrow>x+y=42</mrow>
<mrow>x-y=6</mrow>
</md>
</p>


<p>This one is about as easy as a system of two equations in two variables can get. Actually, that's not quite true.  The <em>easiest</em> form for a system of two equations in two unknowns is if they basically just are statements of the answer, like:

<md>
<mrow>x=24</mrow>
<mrow>y=18.</mrow>
</md>

Solving a system of equations just means (somehow) transforming it from something like the first form to something like this latter form.
</p>

<p>There are a small number of simple procedures that we can apply to systems without effecting their solutions.  We can use these operations to convert almost any system into one that looks like that latter form (each equation just states what the value of some variable is). We'll get around to the full story in section <xref ref="section-sys_eqs" />, but for now, notice that if we add the two original equations together (adding equations means adding left sides and adding right sides separately) we get something that only involves <m>x</m>.  And of course, once we know one of the variables it isn't very hard to find the other.
</p>

<p>We glossed-over a small but important issue in the above.  How do we know that our answer was the only answer?  And for that matter, is it necessarily true that there must <em>be</em> an answer to some system of equations?  These are what are known as existence and uniqueness questions:  Does there exist an answer to our problem?  (Existence.) And, if there <em>is</em> an answer, how do we know it is the only answer? (Uniqueness.)  There are systems of equations where all of the possible behaviors are exhibited: no solutions, unique solutions and lots of solutions.
</p>

<exercise>
  <statement>
    <p>Explain why the following system has no solutions at all.
    <md>
      <mrow>2x - y = 7</mrow>
      <mrow>2y - 4x = 8.</mrow>
    </md>
    </p>
  </statement>
  <hint>
    <p>Put both equations into slope-intercept form (<m>y = mx + b</m>).</p>
  </hint>
</exercise>

<p>
  That was a linear algebra problem seen from the <q>systems of equations</q> perspective. We still need to look at the <q>vector equations</q> and <q>transformations</q> viewpoints. So next we'll look at a question of the vector flavor. We're going to think about playing chess, not on a board, but on the infinite <m>x</m><mdash /><m>y</m> plane.
</p>
<p>
  Consider the piece known as a bishop. If you're not familiar with chess, this is the piece that can move in the diagonal directions. Think of the bishop as having two moves that it can do (but it can do them any number of times). It can do a move we'll refer to as UR; move one unit in the <m>x</m> direction while simultaneously moving one unit in the <m>y</m> direction <mdash /> by doing this multiple times the bishop can travel in the upper right direction. It also has a move that allows it to travel along the other diagonal <mdash /> move one unit in the <m>x</m> direction while simultaneously moving negative one unit in the <m>y</m> direction. We'll call that move LR.
</p>
<p>For those who are familiar with chess, you'll know that bishops are forever trapped on the same color square <mdash /> one of your bishops is always on black and the other always on white. This means that some <q>bishop moving questions</q> won't have solutions <mdash /> for example a bishop sitting at the origin, <m>(0, 0)</m>, can never move to <m>(0, 5)</m>; those squares have opposite colors! To get around this limitation we're going to let our bishops make fractional moves. For instance if it starts at the origin and makes <m>1/2</m> of the upper-right move then it will arrive at <m>(1/2, 1/2)</m>.  Now, getting a little stranger, we're going to also allow our bishops to make negative moves. Maybe we should think of a negative move as <q>undoing</q> a regular move<ellipsis />
</p>


<p>In any case negative moves allow us to move the bishop in the opposite directions along the diagonals.  Finally, we may as well give our bishops the freedom to move <em>any amount</em> <mdash /> that is, any real number can be used as a so-called scalar, shrinking or stretching either of the two basic moves. Got it?
We can do things like <m>\pi \cdot UR</m> and <m>\sqrt{2} \cdot LR</m>.
</p>

<p>So, after all that setup, here's the question: If a bishop starts at <m>(0,0)</m>, can it make some number of UR and LR moves and wind up at <m>(42,6)</m>?  If so, how many URs and how many LRs?
</p>



<p>The things we've been calling UR and LR are <em>vectors</em>.  If you ask someone from the physical sciences to define a vector they'll say <q>it's a thing that has both a magnitude and a direction</q>.
(Which is fine as far as it goes.)  Meteorology provides some nice examples. A weather map often shows a lot of basic data about the conditions at various places <mdash /> wind, temperature, barometric pressure and humidity are common.  Of these, only the wind is a vector quantity, it needs to be specified with both a magnitude and a direction (<eg /> 15 mph out of the Northeast), the others all just have magnitudes.
</p>

<p>There is a different way of thinking about what a vector is, that is preferable in many circumstances.  A vector is the difference between two positions.  Let me put this another way: a vector gives you a set of <em>directions</em> to go from one point to another.  (I mean <q>directions</q> in the sense of the things someone tells you if you ask <q>How do I get to the Kwik-E-Mart from here?</q>)
</p>

<p>If you are currently at the point <m>(3,4)</m> and you want to move to the point <m>(5,12)</m> you
need to increase your <m>x</m>-coordinate by 2 units and you must increase your <m>y</m>-coordinate by 8 units.  We just described the vector <m>\langle 2, 8 \rangle</m>, the numbers <m>2</m> and <m>8</m> are known as the components of the vector.  Note that this is different in a not-so-subtle way from the <em>point</em> <m>(2,8)</m>.  The point is stationary, the vector is there to describe a change.  If you start at the origin and follow the directions specified by the vector <m>\langle 2, 8 \rangle</m> you will of course wind up at the point <m>(2,8)</m>, but if you start at some other point, it's equally obvious that you won't!.  Sometimes people will talk about <q>position vectors</q> in this sort of context <mdash /> the position vector  <m>\langle x,y \rangle</m> goes from the origin to the point  <m>(x,y)</m>.  Generally, it is preferable to keep the distinction between points and vectors clear.  When you treat a vector as a position vector (i.e. think of it as a point) you are loosing something.  Ordinarily a vector is free; it can be slid around from one point to another so long as its components aren't changed.
</p>

<p>So, at this point we've looked at a simple linear algebra problem from the systems of equations perspective and from the vector equations perspective.  The final perspective we want to illustrate is that of linear transformations.
</p>

<p>Basically, a linear transformation is a function that takes vectors as inputs and spits out vectors as outputs.  You're probably familiar with the following sort of diagram for functions.
</p>

<figure>
    <image source="images/function_diagram" width="40%" />
</figure>

<p>In Multivariable Calculus you may also encounter functions that are diagramed like so:
</p>

<sidebyside width="40%" margins="auto">
  <image source="images/function_diagram2" />
  <image source="images/function_diagram3" />
</sidebyside>

<p>The first is a real-valued function of two variables <mdash /> think of it as taking a vector as input and returning a scalar.  The second is a vector-valued function of a single real variable.  The mapping that gives temperature as a function of position on a metal plate is an example of the first sort.  When we represent the position of a particle moving around in space (as a function of time) we are using the second sort.</p>

<p>Linear transformations are functions where there are vectors on both the input and the output side.
</p>

<figure>
    <image source="images/function_diagram4" width="70%" />
</figure>

<p>Moreover, linear transformations are <em>linear</em>, which means the components of the output are computed in a very simplistic way from the components of the inputs.  The only things that are allowed are adding things up and multiplying by constants. 
</p>

<p>So let's give an example of a linear transformation.  This will be a function that takes a vector <m>\langle x, y \rangle</m> as input, and returns a vector <m>\langle u, v \rangle</m> as output.  We will compute <m>u</m> and <m>v</m> (the components of the output vector) from <m>x</m> and <m>y</m> (the components of the input vector by <q>adding things up and multiplying by constants</q>:

<md>
  <mrow>u = x+y</mrow>
  <mrow>v = x-y</mrow>
</md>
</p>

<p>By convention, people usually call a linear transformation <m>T</m> and use a notation that looks just like Euler notation for functions (because in fact, that's what it is!)

<md>
  <mrow> T( \langle x,y \rangle ) = \langle u, v \rangle . </mrow>
</md>

There are two kinds of problems one can ask: maybe you know the input vector and you'd like to find the output vector, or vice versa.  When you've got the input it's very easy to find the output!  You just plug in.  The more interesting question is when it's vice versa, suppose you know that <m>\langle u, v \rangle = \langle 42, 6 \rangle</m> how can you arrive at the solution <m> \langle x,y \rangle  = \langle 24, 18 \rangle </m>?  We'll be looking at this kind of thing in more depth in Section <xref ref="section-transformations" />.
</p>

</section>

<section xml:id="section-sys_eqs">
<title>Systems of equations</title>
<p>In this section we'll look much more closely at the <q>systems of equations</q> approach to linear algebra.</p>

<p>First a few words about notation.  When there are seventeen variables in a problem it becomes <em>really</em> awkward to use different letters for each variable.  When there are a thousand variables it's impossible!  We will follow the almost universal convention that the letter <m>x</m> will be used for the variables, with a subscript to identify which one.  If we were to translate the problem from Section  <xref ref="section-start" /> into this notation it would become

<md>
  <mrow>x_1 + x_2 = 42 </mrow>
  <mrow>x_1 - x_2 = 6. </mrow>
</md>
</p>

<p>A <em>linear combination</em> of some set of numbers <m>\{ x_1, x_2, \ldots, x_n \}</m> is created by multiplying each of the <m>x</m>'s by constants and then adding everything up. Of course if the constants are <m>1</m> or <m>-1</m> (as in the previous example) we tend to forget that they're there!
</p>

<example>
  <p>Consider <m>x_1 + 2x_2 + 3x_3 + 4x_4 + 5x_5</m>. This is a linear combination of the five variables <m>\{x_1, x_2, x_3, x_4, x_5\}</m>.  The constants (<m>1, 2, 3, 4,</m> and <m>5</m>) are called the coefficients of the linear combination.
  </p>
</example>

<p>An equation is <em>linear</em> if it has the form of a linear combination set equal to some value on the right-hand side -- or if it can be put into that form.  For example

<md>
  <mrow> x_1 + 2x_2 + 3x_3 + 4x_4 + 5x_5 = 15 </mrow>
</md>

is a linear equation in five variables.
</p>

<p>Also,
<md>
  <mrow> x_1 + 3x_3 = x_2 + x_4 </mrow>
</md>

is a linear equation (in four variables) because we can manipulate it into the form

<md>
  <mrow> x_1 - x_2 + 3x_3 - x_4 = 0. </mrow>
</md>
</p>

<exercise>
  <statement>
    <p>The linear equation
<md>
  <mrow> x_1 + 2x_2 + 3x_3 + 4x_4 + 5x_5 = 15 </mrow>
</md>

has a solution where all of the variables are set equal to 1.  Are there others?
    </p>
  </statement>
  <hint>
    <p>Try setting one of the variables to zero.  That essentially eliminates that one and gives you a new equation with only four variables.  Does the new equation have a solution?
    </p>
  </hint>
</exercise>

<p>A <em>system of equations</em> is just a collection of linear equations.</p>

<p>The notation for systems of equations gets a bit complicated when we try to write them in general (that is, without particular values given for the various constants involved).  There are three sorts of things that need names in such a system: the variables, the coefficients of the variables, and the numbers on the right-hand sides.  There is a convention that is fairly universal for the names and numbering of these elements.  The variables are <m>x</m>'s with subscripts, the right-hand sides are <m>b</m>'s with subscripts, and the coefficients are <m>a</m>'s with <em>two</em> subscripts (we need to indicate the equation that a given coefficient is in and also, which variable it is multiplying.
</p>

<p>For example, here is how we would write the general form of a system of three equations in four unknowns:
 
<me>
\begin{alignedat}{5}
\aij{1}{1} x_1 \amp {}+{} \amp  \aij{1}{2} x_2 \amp {}+{} \amp \aij{1}{3} x_3 \amp {}+{} \amp  \aij{1}{4} x_4 \amp {}={} \amp b_1 \\
\aij{2}{1} x_1 \amp {}+{} \amp  \aij{2}{2} x_2 \amp {}+{} \amp \aij{2}{3} x_3 \amp {}+{} \amp  \aij{2}{4} x_4 \amp {}={} \amp b_2 \\
\aij{3}{1} x_1 \amp {}+{} \amp  \aij{3}{2} x_2 \amp {}+{} \amp \aij{3}{3} x_3 \amp {}+{} \amp  \aij{3}{4} x_4 \amp {}={} \amp b_3 \\
\end{alignedat}
</me>

Notice that the indices on the <m>x</m>'s run from 1 to 4, the indices on the <m>b</m>'s run from 1 to 3, and that there are a total of 12 coefficients.
</p>
  
<example xml:id="ex-invest">
<title>Investments</title>
<statement>
<p>Suppose you have <dollar /><m>10,000</m> that you want to invest in the stock market. After some research you've found three companies that you think will be good investments.  SolarCity Corp (SCTY) is trading at about <dollar /><m>20</m> per share.  SunPower - Solar energy company (SPWR) is trading at about <dollar /><m>9</m> per share. First Trust Global Wind Energy (FAN) is at about <dollar /><m>12</m> per share.  One equation you can immediately write down is

<md>
<mrow>20 x_1 + 9 x_2 + 12 x_3 = 10000,</mrow>
</md>

where <m>x_1</m> is the number of shares of SCTY we will buy, <m>x_2</m> is the number of shares of SPWR, and <m>x_3</m> is the number of shares of FAN.
</p>

<p>If we said nothing further, we'd have just this one equation and there are many possible sets of values for the variables that satisfy it.  Notice that there are two broad categories of companies represented in our stock picks -- solar energy and wind power.  Perhaps we'd be wise to split our investment between them based on some rational theory, for the sake of argument let's say that we've been advised to use a 60/40 split between solar and wind.  What was previously a single equation is now two:

<md>
<mrow>20 x_1 + 9 x_2 = 60000,</mrow>
<mrow>12 x_3 = 40000.</mrow>
</md>
</p>

<p>Notice that the second equation uniquely determines the value of <m>x_3</m> but that the other variables still have a bit of freedom.  (For instance, notice that we could set either <m>x_1</m> or <m>x_2</m> to <m>0</m>, and the other variable's value would then be uniquely determined. Or, of course we could have some mixture where our <dollar /><m>6,000</m> is split up between the two companies.  As it happens, these two companies are competitors and there is some probability that one will succeed and the other will fail.  A wise investor tries to guess what that probability is and <q>hedge</q> their bets on the market.  For the sake of argument let's say we think SCTY is three times more likely to come out the winner in this competition.  You might be inclined to just buy only the SCTY stock, but that's not what a hedging strategy would indicate -- you should mix your investments in a proportion that reflects the probabilities involved.  As an equation in the <m>x</m>'s we have

<md>
<mrow>20 x_1 = 3 \cdot 9 x_2.</mrow>
</md>
</p>

<p>At this point we've obtained a system of 3 equations in 3 variables which, after manipulating the last one a little bit, looks like the following.

<md>
<mrow>20 x_1 + 9 x_2 = 60000</mrow>
<mrow>12 x_3 = 40000</mrow>
<mrow>20 x_1 - 27 x_2 = 0</mrow>
</md>
</p>

<p>It is usually a good idea to format your systems so that the variables in each equation line up in columns.

<me>
\begin{alignedat}{4}
20 x_1 \amp {}+{} \amp  9 x_2 \amp {}+{} \amp  \amp {}={} \amp 6000 \\
 \amp  \amp   \amp  \amp  12 x_3 \amp {}={} \amp 4000 \\
20 x_1 \amp {}-{} \amp 27 x_2 \amp  \amp  \amp {}={} \amp 0
\end{alignedat}
</me>
</p>
</statement>

<solution>
<p>Now, let's go ahead and figure out what the values of the variables should be.  In other words, how many shares of each stock should we purchase?
</p>
  
<p>First, look at that middle equation.  It isn't very complicated, indeed, it basically <em>tells</em> us the value of <m>x_3</m> <mdash /> we just need to divide both sides by 12 to get that <m>x_3 = 333.\overline{3}</m>.  Unfortunately, we can't buy fractions of a share of stock so we'll round to <m>333</m>.
</p>

<p>We're somewhat lucky in that the variable <m>x_3</m> doesn't appear in the other equations, but <em>even if it did</em>, we could now substitute the value we just determined for it.  Furthermore, at this point, we have no more use for that middle equation; we've used it up in finding the value of <m>x_3</m>.  So now we've reduced our problem to a simpler system <mdash /> one that consists of just two equations in the remaining two unknowns.

<me>
\begin{alignedat}{3}
20 x_1 \amp {}+{} \amp  9 x_2   \amp {}={} \amp 6000 \\
20 x_1 \amp {}-{} \amp 27 x_2   \amp {}={} \amp 0
\end{alignedat}
</me>
</p>

<p>If we subtract the first equation from the second we get
<me>
\begin{alignedat}{3}
  \amp {}-{} \amp 36 x_2   \amp {}={} \amp -6000
\end{alignedat}
</me>
and this tells us (just divide both sides by <m>-36</m>) the value of <m>x_2</m>. 
</p>

<p>What we've determined so far is that <m>x_3 = 333</m> and <m>x_2 = 167</m>. By substituting those values into the very first equation we wrote down we'll be able to find the value of <m>x_1</m>.
</p>

<p>After making those substitutions we get an equation that only has one variable:

<md>
<mrow>20 x_1 + 9 \cdot 167 + 12 \cdot 333 = 10000.</mrow>
</md>

It's child's play to find the solution is <m>x_3=225</m>.

So in the end we should put in an order for 225 share of SCTY, 167 shares of SPWR and 333 shares of FAN.  Notice that because of rounding we've come up one dollar short of our intended investment.
</p>
</solution>
</example>

<p>A bit more formalism is appropriate now.  We'll start with some definitions.
</p>

<definition>
<title>linear system</title>
<index><main>linear system</main>
</index>

<statement><p>A <term>linear system</term>, also known (a bit more formally) as a <term>system of linear equations</term> is a collection of <m>m</m> equations in <m>n</m> unknowns of the form
<me>
\begin{alignedat}{5}
a_{11} x_1 \amp {}+{} \amp  a_{12} x_2 \amp {}+{} \amp  \amp {}\cdot {} \amp \amp {}+{} a_{1n} x_n \amp {}={} \amp b_1 \\
a_{21} x_1 \amp {}+{} \amp  a_{22} x_2 \amp {}+{} \amp  \amp {}\cdot {} \amp \amp {}+{} a_{2n} x_n \amp {}={} \amp b_2 \\
 \amp \amp \amp  \amp \amp \vdots \amp  \amp \amp \amp \\
a_{m1} x_1 \amp {}+{} \amp  a_{m2} x_2 \amp {}+{} \amp  \amp {}\cdot {} \amp \amp {}+{} a_{mn} x_n \amp {}={} \amp b_m \\
\end{alignedat}
</me>
</p>

<p>Note that the doubly-indexed quantities (<m>a_{ij}</m>) as well as the singly-indexed quantities (<m>b_i</m>) are real numbers and that the <m>m</m> variables are indicated by <m>x</m>'s (with subscripts).
</p>
</statement>
</definition>
<remark><p>The use of variables with multiple indices in the above definition bears comment.  First of all, note that we are trying to deal with the general situation where there is an unknown number of equations (<m>m</m>) in an unknown number of variables (<m>n</m>).  Let's consider the <m>b</m>'s first <mdash /> these are the constants that appear on the right-hand sides of the equations, so there are <m>m</m> of them.  The situation for the <m>a</m>'s is more complicated.  The <m>a</m>'s are the coefficients, they are constant numbers that the variables are multiplied by, and there are two indices on each of them.  The first index tells us which equation we are in.  The second index matches with the subscript on the variable.  For example <m>\aij{14}{23}</m> would be the coefficient of <m>x_{23}</m> in the <m>14</m>th equation in a system.
</p> 
</remark>

<p>What does it means to say we have found an <q>answer</q> to a system of equations?  Essentially, it is this: we have found a set of values for the variables that <q>work</q> in all of the equations.  Sometimes people say that this set of values <q>satisfies</q> the equations.  To be completely clear, what is meant is that if one substitutes these values for the variables in the equations of the system, all of them (the equations) will be true.  It is convenient to regard such a set of values as a vector.  For example the solution we obtained in Example <xref ref="ex-invest" /> would be regarded as the vector <m>\langle 225, 167, 333 \rangle</m>.
</p>


<definition>
<title>solution sets</title>
<index><main>solution sets</main>
</index>
<statement>
<p>Given a system of <m>m</m> linear equations in <m>n</m> unknowns, the <term>solution set</term> of the system is the set of all vectors of length <m>n</m> that satisfy all <m>m</m> of the equations in the system.
</p>
</statement>
</definition>

<definition>
<title>equivalent systems</title>
<index><main>equivalence of linear systems</main>
</index>
<statement>
<p>Two linear systems are called <term>equivalent</term> if and only if they have identical solution sets.
</p>
</statement>
</definition>
<remark>
<p>The equivalence of linear systems is an example of what is known  as an equivalence relation.  Equivalence relations are used in theoretical mathematics when we are trying to capture the notion that two things <mdash /> while not <em>actually</em> equal <mdash /> are similar enough that we can treat them as being sort of a junior version of equal<ellipsis />  
</p>
<p>For a relationship to earn the title <q>equivalence relation</q> it must have a short list of properties.  These properties are certainly true of the ordinary equals sign:
</p>

<dl>
<li><title>reflexivity</title><p>A relation is reflexive iff all elements are related to themselves.</p>
<li><title>symmetry</title><p>A relation is symmetric iff whenever <m>x</m> and <m>y</m> are a pair of elements that are related, then <m>y</m> and <m>x</m> are also a pair that are related.  (I.e. the order can always be reversed.) 
<li><title>transitivity</title><p>Perhaps you've heard the phrase <q>Two things that are equal to a third must be equal to each other.</q> That's the essence of transitivity.</p>
</dl>
<p>
There really is much more that we should say about equivalence relations in general and the consequences that ensue when we can show that some relation is an equivalence relation.  We refer the interested reader to chapter 6 in <url href="https://osj1961.github.io/giam/">GIAM</url>. For our present purposes, we are about to <em>see</em> how very useful the notion of equivalence of linear systems can be.  Hopefully this will give you some indication of how useful equivalence relations in general can be!  
</p>
  
<p>One final word about equivalence relations (in general) and the equivalence of linear systems (in particular):  It is customary, when introducing this notion, to ask students to come up with a proof that shows that some given relation (in this case, equivalence of linear systems) is indeed an equivalence relation.  Such proofs are actually relatively straightforward, but <em>relax</em>, we're going to let you off the hook this time!  Showing that equivalence of linear systems is an equivalence relation is actually too easy.  What one needs to do is show that it has each of the three properties: reflexivity, symmetry and transitivity.  Each of those is an almost immediate consequence of the way this equivalence is defined.  We define two systems to be equivalent if and only if they have the same solution set. In other words, equivalence is <em>defined</em> in terms of set equality.  Set equality is definitely an equivalence relation, so it has the three properties.  Finally, the arguments that show that equivalence of linear systems has the three properties all have the same form: in order to show that the equivalence of linear systems has a property we use the fact that set equality has that property.  This is called inheritance.  
</p>
</remark>

<p>The general idea is this:  there are lots and lots of different linear systems that are equivalent.  They all have the same solution set.  Some of these systems are in a nice form that allows us to see what the solution set is.  Others are not.  We need to transform the latter into the former!
</p>

<p>More specifically, there are three operations that can be applied to linear systems which <em>do not have any effect on solution sets</em>.  We can apply these three operations in any way we like!  We'll just be transforming our linear system into a slightly different one that is equivalent to the original.  Finally, you'll see that it is pretty easy to strategize a bit and transform difficult linear systems into the nice sort where the solution set is very evident using these three operations.
</p> 

<p>The three operations go by many names; we'll refer to them as Reordering, Scaling and Combining.  In the next few paragraphs we'll discuss each of them in turn and explain why they don't have an effect on the solution set of a system.
</p>

<p><em>Reordering</em> means what it sounds like.  The solution set is determined by checking whether a given solution vector satisfies <em>all</em> of the equations.  It is pretty clear that the order that the equations are listed in is of little importance.  In many treatments of linear algebra an operation called <q>swapping</q> is used instead <mdash /> swapping two equations is a special (particularly simple) instance of reordering and any more general reordering can be accomplished by a succession of swaps.
</p>

<exercise>
</section>

<section xml:id="section-vectors">
<title>Vector equations</title>
<p>.</p>
</section>

<section xml:id="section-transformations">
<title>Transformations</title>
<p>Dummy text for introduction.</p>
</section>

<section>
<title>Matrix notation</title>
<p>Dummy text for introduction.</p>
</section>

</chapter>
