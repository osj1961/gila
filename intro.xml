<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns:xi="http://www.w3.org/2001/XInclude">
<title>Introduction</title>

<introduction>
<p>The subject we are about to study, Linear Algebra, sounds like it might have something to do with lines and doing algebra with them.  This is true if you are willing to think metaphorically<ellipsis /> It might be somewhat closer to the truth if we were to say that Linear Algebra is about learning to understand higher dimensions.  We'll be surprisingly far along in our study of the topic before we can precisely define what <q>dimension</q> actually means, but we expect that you have some notion already: the Euclidean plane where we studied Geometry is two dimensional, the world we live in is three dimensional, Albert Einstein taught us to view the world not just as space <mdash /> but as space-time <mdash /> a four dimensional concept.  We needn't jump off into super advanced physics (or science fiction for that matter) in order to understand higher dimensionality.  Dimension, at least informally, just means the number of real numbers it takes to describe something. Locating a point in three-dimensional space requires three numbers <mdash /> usually <m>x</m>, <m>y</m> and <m>z</m>.  If we are keeping track of aircraft, knowing where they are in 3-space is certainly necessary, but it might also be a good idea to keep abreast of <em>which way they are going</em>!  To truly understand an aircraft's state, one needs to have six numbers: <m>x</m>, <m>y</m> and <m>z</m>, but also the velocity components <m>x'</m>, <m>y'</m> and <m>z'</m>.  This make the state of an airplane 6-dimensional.  Perhaps this is why air traffic controllers make the big bucks.
</p>

<p>The 6-dimensionality of an aircraft's state may seem somewhat artificial.  Aren't we really just dealing with two separate 3-dimensional entities?
</p>

<p>In Economics there is a high-dimensional entity known as the Leontief Input-Output model.  In
this model the state of an Economic system is described by a large number of real quantities, one for each sector of the economy.  In a 1965 Scientific American article Wassily Leontief (who won a Nobel prize for this work) described his model in terms of a <q>toy example</q> where the economy was divided into 82 sectors.  Today one could easily develop a Leontief I/O model where the economy was divided up into a million sectors.  Perhaps this is why Economists make even bigger bucks.
</p>

<p>When we do Linear Algebra in two dimensions we are indeed talking about lines.  One of the classic problems is to figure out whether two lines intersect and if so, where.  This is a situation where our ability to visualize things in two dimensions can lead us straight to the answer.  That is certainly not the case in a million (or even in six) dimensions.  Fortunately, there are calculational techniques that work (and even work fairly quickly on a good computer) in
just about any number of dimensions you may be interested in.
</p>

<p>There are three different ways of looking at linear algebra problems: systems of linear equations, vector equations, and transformations.  These three views actually represent the same underlying structure, just in different ways.  There are various situations where one of these three viewpoints is preferable, so it is a good idea to be able to switch back and forth between these representations.
</p>

<p>In Section <xref ref="section-start" /> we will look at the same (really easy) problem from each of these 3 perspectives.
</p>

</introduction>

<section xml:id="section-start">
<title>Getting started</title>
<p>The first problem we're going to look at is fairly trivial.  I bet you can solve this in your head:</p>

<blockquote>
  <p>I'm thinking of two numbers <m>x</m> and <m>y</m>.  Their sum is 42, and their difference is 6.  What are they?</p>
</blockquote>

<p>This word problem can be instantly translated into a pair of equations.  Later, when we have more sophisticated problems there may be many more unknown quantities and there may be many more equations.  Here we are dealing with a system of equations having 2 equations in 2 unknowns.

<md>
<mrow>x+y=42</mrow>
<mrow>x-y=6</mrow>
</md>
</p>


<p>This one is about as easy as a system of two equations in two variables can get. Actually, that's not quite true.  The <em>easiest</em> form for a system of two equations in two unknowns is if they basically just are statements of the answer, like:

<md>
<mrow>x=24</mrow>
<mrow>y=18.</mrow>
</md>

Solving a system of equations just means (somehow) transforming it from something like the first form to something like this latter form.
</p>

<p>There are a small number of simple procedures that we can apply to systems without effecting their solutions.  We can use these operations to convert almost any system into one that looks like that latter form (each equation just states what the value of some variable is). We'll get around to the full story in section <xref ref="section-sys_eqs" />, but for now, notice that if we add the two original equations together (adding equations means adding left sides and adding right sides separately) we get something that only involves <m>x</m>.  And of course, once we know one of the variables it isn't very to find the other.
</p>

<p>We glossed-over a small but important issue in the above.  How do we know that our answer was the only answer?  And for that matter, is it necessarily true that there must <em>be</em> an answer to some system of equations?  These are what are known as existance and uniqueness questions:  Does there exist an answer to our problem?  (Existance.) And, if there <em>is</em> an answer, how do we know it is the only answer? (Uniqueness.)  There are systems of equations where all of the possible behaviors are exhibited: no solutions, unique solutions and lots of solutions.
</p>

<exercise>
  <statement>
    <p>Explain why the following system has no solutions at all.
    <md>
      <mrow>2x - y = 7</mrow>
      <mrow>2y - 4x = 8.</mrow>
    </md>
    </p>
  </statement>
  <hint>
    <p>Put both equations into slope-intercept form (<m>y = mx + b</m>).</p>
  </hint>
</exercise>

<p>
  That was a linear algebra problem seen from the <q>systems of equations</q> perspective. We still need to look at the <q>vector equations</q> and <q>transformations</q> viewpoints. So next we'll look at a question of the vector flavor. We're going to think about playing chess, not on a board, but on the infinite <m>x</m><mdash /><m>y</m> plane.
</p>
<p>
  Consider the piece known as a bishop. If you're not familiar with chess, this is the piece that can move in the diagonal directions. Think of the bishop as having two moves that it can do (but it can do them any number of times). It can do a move we'll refer to as UR; move one unit in the <m>x</m> direction while simultaneously moving one unit in the <m>y</m> direction <mdash /> by doing this multiple times the bishop can travel in the upper right direction. It also has a move that allows it to travel along the other diagonal <mdash /> move one unit in the <m>x</m> direction while simultaneously moving negative one unit in the <m>y</m> direction. We'll call that move LR.
</p>
<p>For those who are familiar with chess, you'll know that bishops are forever trapped on the same color square <mdash /> one of your bishops is always on black and the other always on white. This means that some <q>bishop moving questions</q> won't have solutions <mdash /> for example a bishop sitting at the origin, <m>(0, 0)</m>, can never move to <m>(0, 5)</m>; those squares have opposite colors! To get around this limitation we're going to let our bishops make fractional moves. For instance if it starts at the origin and makes <m>1/2</m> of the upper-right move then it will arrive at <m>(1/2, 1/2)</m>.  Now, getting a little stranger, we're going to also allow our bishops to make negative moves. Maybe we should think of a negative move as <q>undoing</q> a regular move<ellipsis />
</p>


<p>In any case negative moves allow us to move the bishop in the opposite directions along the diagonals.  Finally, we may as well give our bishops the freedom to move <em>any amount</em> <mdash /> that is, any real number can be used as a so-called scalar, shrinking or stretching either of the two basic moves. Got it?
We can do things like <m>\pi \cdot UR</m> and <m>\sqrt{2} \cdot LR</m>.
</p>

<p>So, after all that setup, here's the question: If a bishop starts at <m>(0,0)</m>, can it make some number of UR and LR moves and wind up at <m>(42,6)</m>?  If so, how many URs and how many LRs?
</p>



<p>The things we've been calling UR and LR are <em>vectors</em>.  If you ask someone from the physical sciences to define a vector they'll say <q>it's a thing that has both a magnitude and a direction</q>.
(Which is fine as far as it goes.)  Meteorology provides some nice examples. A weather map often shows a lot of basic data about the conditions at various places <mdash /> wind, temperature, barometric pressure and humidity are common.  Of these, only the wind is a vector quantity, it needs to be specified with both a magnitude and a direction (<eg /> 15 mph out of the Northeast), the others all just have magnitudes.
</p>

<p>There is a different way of thinking about what a vector is, that is preferable in many circumstances.  A vector is the difference between two positions.  Let me put this another way: a vector gives you a set of <em>directions</em> to go from one point to another.  (I mean <q>directions</q> in the sense of the things someone tells you if you ask <q>How do I get to the Kwik-E-Mart from here?</q>)
</p>

<p>If you are currently at the point <m>(3,4)</m> and you want to move to the point <m>(5,12)</m> you
need to increase your <m>x</m>-coordinate by 2 units and you must increase your <m>y</m>-coordinate by 8 units.  We just described the vector <m>\langle 2, 8 \rangle</m>, the numbers <m>2</m> and <m>8</m> are known as the components of the vector.  Note that this is different in a not-so-subtle way from the <em>point</em> <m>(2,8)</m>.  The point is stationary, the vector is there to describe a change.  If you start at the origin and follow the directions specified by the vector <m>\langle 2, 8 \rangle</m> you will of course wind up at the point <m>(2,8)</m>, but if you start at some other point, it's equally obvious that you won't!.  Sometimes people will talk about <q>position vectors</q> in this sort of context <mdash /> the position vector  <m>\langle x,y \rangle</m> goes from the origin to the point  <m>(x,y)</m>.  Generally, it is preferable to keep the distinction between points and vectors clear.  When you treat a vector as a position vector (i.e. think of it as a point) you are loosing something.  Ordinarily a vector is free; it can be slid around from one point to another so long as its components aren't changed.
</p>

<p>So, at this point we've looked at a simple linear algebra problem from the systems of equations perspective and from the vector equations perspective.  The final perspective we want to illustrate is that of linear transformations.
</p>

<p>Basically, a linear transformation is a function that takes vectors as inputs and spits out vectors as outputs.  You're probably familiar with the following sort of diagram for functions.
</p>

<image source="images/function_diagram.svg" />

<p>In Multivariable Calculus you may also encounter functions that are diagramed like so:
</p>

<sidebyside margins="5" widths="40% 40%" valign="middle">
  <image source="images/function_diagram2.svg" />
  <image source="images/function_diagram3.svg" />
</sidebyside>

<p>The first is a real-valued function of two variables <mdash /> think of it as taking a vector as input and returning a scalar.  The second is a vector-valued function of a single real variable.  The mapping that gives temperature as a function of position on a metal plate is an example of the first sort.  When we represent the position of a particle moving around in space (as a function of time) we are using the second sort.</p>

<p>Linear transformations are functions where there are vectors on both the input and the output side.
</p>

<image source="images/function_diagram4.svg" />

<p>Moreover, linear transformations are <em>linear</em>, which means the components of the output are computed in a very simplistic way from the components of the inputs.  The only things that are allowed are adding things up and multiplying by constants. 
</p>

<p>So let's give an example of a linear transformation.  This will be a function that takes a vector <m>\langle x, y \rangle</m> as input, and returns a vector <m>\langle u, v \rangle</m> as output.  We will compute <m>u</m> and <m>v</m> (the components of the output vector) from <m>x</m> and <m>y</m> (the components of the input vector by <q>adding things up and multiplying by constants</q>:

<md>
  <mrow>u = x+y</mrow>
  <mrow>v = x-y</mrow>
</md>
</p>

<p>By convention, people usually call a linear transformation <m>T</m> and use a notation that looks just like Euler notation for functions (because in fact, that's what it is!)

<md>
  <mrow> T( \langle x,y \rangle ) = \langle u, v \rangle . </mrow>
</md>

There are two kinds of problems one can ask: maybe you know the input vector and you'd like to find the output vector, or vice versa.  When you've got the input it's very easy to find the output!  You just plug in.  The more interesting question is when it's vice versa, suppose you know that <m>\langle u, v \rangle = \langle 42, 6 \rangle</m> how can you arrive at the solution <m> \langle x,y \rangle  = \langle 24, 18 \rangle </m>?  We'll be looking at this kind of thing in more depth in Section <xref ref="section-transformations" />.
</p>

</section>

<section xml:id="section-sys_eqs">
<title>Systems of equations</title>
<p>In this section we'll look much more closely at the <q>systems of equations</q> approach to linear algebra.</p>

<p>First a few words about notation.  When there are seventeen variables in a problem it becomes <em>really</em> awkward to use different letters for each variable.  When there are a thousand variables it's impossible!  We will follow the almost universal convention that the letter <m>x</m> will be used for the variables, with a subscript to identify which one.  If we were to translate the problem from Section  <xref ref="section-start" /> into this notation it would become

<md>
  <mrow>x_1 + x_2 = 42 </mrow>
  <mrow>x_1 - x_2 = 6. </mrow>
</md>
</p>

<p>A <em>linear combination</em> of some set of numbers <m>\{ x_1, x_2, \ldots, x_n \}</m> is created by multiplying each of the <m>x</m>'s by a constant and add them all up. Of course if the constants are <m>1</m> or <m>-1</m> (as in the previous example) we tend to forget that they're there!
</p>

<example>
  <p>Consider <m>x_1 + 2x_2 + 3x_3 + 4x_4 + 5x_5</m>. This is a linear combination of the five variables <m>\{x_1, x_2, x_3, x_4, x_5\}</m>.  The constants <m>1, 2, 3, 4,</m> and <m>5</m> are called the coefficients of the linear combination.
  </p>
</example>

<p>An equation is <em>linear</em> if it has the form of a linear combination set equal to some value on the right-hand side -- or if it can be put into that form.  For example

<md>
  <mrow> x_1 + 2x_2 + 3x_3 + 4x_4 + 5x_5 = 15 </mrow>
</md>

is a linear equation in five variables.
</p>

<p>Also,
<md>
  <mrow> x_1 + 3x_3 = x_2 + x_4 </mrow>
</md>

is a linear equation (in four variables) because we can manipulate it into the form

<md>
  <mrow> x_1 - x_2 + x_3 - x_4 = 0. </mrow>
</md>
</p>

<exercise>
  <statement>
    <p>The linear equation
<md>
  <mrow> x_1 + 2x_2 + 3x_3 + 4x_4 + 5x_5 = 15 </mrow>
</md>

has a solution where all of the variables are set equal to 1.  Are there others?
    </p>
  </statement>
  <hint>
    <p>Try setting one of the variables to zero.  That essentially eliminates that one and gives you a new equation with only four variables.  Does the new equation have a solution?
    </p>
  </hint>
</exercise>

<p>A <em>system of equations</em> is just a collection of linear equations.</p>

<example>
<title>Investments</title>
<statement>
<p>Suppose you have $<m>10,000</m> that you want to invest in the stock market. After some research you've found three companies that you think will be good investments.  SolarCity Corp (SCTY) is trading at about $<m>20</m> per share.  SunPower - Solar energy company (SPWR) is trading at about $<m>9</m> per share. First Trust Global Wind Energy (FAN) is at about $<m>12</m> per share.  One equation you can immediately write down is

<md>
<mrow>20 x_1 + 9 x_2 + 12 x_3 = 10000,</mrow>
</md>

where <m>x_1</m> is the number of shares of SCTY we will buy, <m>x_2</m> is the number of shares of SPWR, and <m>x_3</m> is the number of shares of FAN.
</p>

<p>If we said nothing further, we'd have just this one equation and there are many possible sets of values for the variables that satisfy it.  Notice that there are two broad categories of companies represented in our stock picks -- solar energy and wind power.  Perhaps we'd be wise to split our investment between them based on some rational theory, for the sake of argument let's say that we've been advised to use a 60/40 split between solar and wind.  What was previously a single equation is now two:

<md>
<mrow>20 x_1 + 9 x_2 = 60000,</mrow>
<mrow>12 x_3 = 40000.</mrow>
</md>
</p>

<p>Notice that the second equation uniquely determines the value of <m>x_3</m> but that the other variables still have a bit of freedom.  (For instance, notice that we could set either <m>x_1</m> or <m>x_2</m> to <m>0</m>, and the other variable's value would then be uniquely determined. Or, of course we could have some mixture where our $<m>6,000</m> is split up between the two companies.  As it happens, these two companies are competitors and there is some probability that one will succeed and the other will fail.  A wise investor tries to guess what that probability is and <q>hedge</q> their bets on the market.  For the sake of argument let's say we think SCTY is three times more likely to come out the winner in this competition.  You might be inclined to just buy only the SCTY stock, but that's not what a hedging strategy would indicate -- you should mix your investments in a proportion that reflects the probabilities involved.  As an equation in the <m>x</m>'s we have

<md>
<mrow>20 x_1 = 3 \cdot 9 x_2.</mrow>
</md>
</p>

<p>At this point we've obtained a system of 3 equations in 3 variables which, after manipulating the last one a little bit, looks like the following.

<md>
<mrow>20 x_1 + 9 x_2 = 60000</mrow>
<mrow>12 x_3 = 40000</mrow>
<mrow>20 x_1 - 27 x_2 = 0</mrow>
</md>
</p>

<p>It is usually a good idea to format your systems so that the variables in each equation line up in columns.

<me>
\begin{alignedat}{4}
20 x_1 \amp {}+{} \amp  9 x_2 \amp {}+{} \amp  \amp {}={} \amp 6000 \\
 \amp  \amp   \amp  \amp  12 x_3 \amp {}={} \amp 4000 \\
20 x_1 \amp {}-{} \amp 27 x_2 \amp  \amp  \amp {}={} \amp 0
\end{alignedat}
</me>
</p>
</statement>
</example>

</section>

<section xml:id="section-vectors">
<title>Vector equations</title>
<p>.</p>
</section>

<section xml:id="section-transformations">
<title>Transformations</title>
<p>Dummy text for introduction.</p>
</section>

<section>
<title>Matrix notation</title>
<p>Dummy text for introduction.</p>
</section>

</chapter>
